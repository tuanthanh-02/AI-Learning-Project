{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Project: project_name\n",
    "    \n",
    "\n",
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "*\n",
    "*\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About The Dataset\n",
    "The original source of the data is \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import the required libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exectue the following cells to install and import the necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cells to load the dataset as a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all rows with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna()\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Granularity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting a feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the feature and target dataframes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop(columns='...', axis=1)\n",
    "# y = df['...']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How balanced are the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can you conclude from these counts?\n",
    "- How often ...?\n",
    "- How accurate would you be if ...?\n",
    "- Is this a balanced dataset?\n",
    "- Next steps?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets, ensuring target stratification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define preprocessing transformers for numerical and categorical features\n",
    "## Automatically detect numerical and categorical columns and assign them to separate numeric and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_features = X_train.select_dtypes(include=['number']).columns.tolist()  \n",
    "# categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define separate transformers for both feature types and combine them into a single preprocessing transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale the numeric features\n",
    "# numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "# # One-hot encode the categoricals \n",
    "# categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the transformers into a single preprocessing column transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numeric_transformer, numeric_features),\n",
    "#         ('cat', categorical_transformer, categorical_features)\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a pipeline by combining the preprocessing with a Random Forest classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('classifier', RandomForestClassifier(random_state=42))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a parameter grid to use in a cross validation grid search model optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'classifier__n_estimators': [50, 100],\n",
    "#     'classifier__max_depth': [None, 10, 20],\n",
    "#     'classifier__min_samples_split': [2, 5]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline usage in crossvalidation\n",
    "Recall that the pipeline is repeatedly used within the crossvalidation by fitting on each internal training fold and predicting on its corresponding validation fold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform grid search cross-validation and fit the best model to the training data\n",
    "### Select a cross-validation method, ensuring target stratification during validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and fit GridSearchCV to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='accuracy', verbose=2)  \n",
    "# grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the best parameters and best crossvalidation score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nBest parameters found: \", grid_search.best_params_)\n",
    "# print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display your model's estimated score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_score = grid_search.score(X_test, y_test)  \n",
    "# print(\"Test set score: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the model predictions from the grid search estimator on the unseen data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = grid_search.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "# disp.plot(cmap='Blues')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importances\n",
    "Recall that to obtain the categorical feature importances, we have to work our way backward through the modelling pipeline to associate the feature importances with their original input variables, not the one-hot encoded ones. We don't need to do this for the numeric variables because we didn't modify their names in any way.  \n",
    "Remember we went from categorical features to one-hot encoded features, using the 'cat' column transformer.\n",
    " \n",
    "Let's get all of the feature importances and associate them with their transformed features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the feature importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importances = grid_search.best_estimator_['classifier'].feature_importances_\n",
    "# feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's extract the feature importances and plot them as a bar graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine numeric and categorical feature names\n",
    "# feature_names = numeric_features + list(grid_search.best_estimator_['preprocessor']\n",
    "#                                         .named_transformers_['cat']\n",
    "#                                         .named_steps['onehot']\n",
    "#                                         .get_feature_names_out(categorical_features))\n",
    "\n",
    "# feature_importances = grid_search.best_estimator_['classifier'].feature_importances_\n",
    "\n",
    "# importance_df = pd.DataFrame({'Feature': feature_names,\n",
    "#                               'Importance': feature_importances\n",
    "#                              }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# N = 20  # Change this number to display more or fewer features\n",
    "# top_features = importance_df.head(N)\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.barh(top_features['Feature'], top_features['Importance'], color='skyblue')\n",
    "# plt.gca().invert_yaxis()  # Invert y-axis to show the most important feature on top\n",
    "# plt.title(f'Top {N} Most Important Features in predicting whether it will rain today')\n",
    "# plt.xlabel('Importance Score')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try another model\n",
    "\n",
    "## Update the pipeline and the parameter grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.set_params(classifier=LogisticRegression(random_state=42))\n",
    "\n",
    "# grid_search.estimator = pipeline\n",
    "\n",
    "# param_grid = {\n",
    "#     'classifier__solver': ['liblinear'],\n",
    "#     'classifier__penalty': ['l1', 'l2'],\n",
    "#     'classifier__class_weight': [None, 'balanced']\n",
    "# }\n",
    "\n",
    "# grid_search.param_grid = param_grid\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = grid_search.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Compare the results to your previous model.\n",
    "Display the clasification report and the confusion matrix for the new model and compare your results with the previous model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Generate the confusion matrix \n",
    "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d')\n",
    "\n",
    "# # Set the title and labels\n",
    "# plt.title('Titanic Classification Confusion Matrix')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Actual')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you conclude about the model performances? \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "prev_pub_hash": "6a00a703e123bddd6178a90cb7938f215f09b4ca3e08ba1f30d34b01603dd863"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
