{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0101EN-SkillsNetwork/images/IDSN-logo.png\" width=\"400\"> </a>\n",
    "\n",
    "# Classification Models with Keras\n",
    "\n",
    "Estimated time needed: **30** mins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will learn how to use the Keras library to build models for classificaiton problems. We will use the popular MNIST dataset, a dataset of images, for a change. \n",
    "\n",
    "The <strong>MNIST database</strong>, short for Modified National Institute of Standards and Technology database, is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning.\n",
    "    \n",
    "The MNIST database contains 60,000 training images and 10,000 testing images of digits written by high school students and employees of the United States Census Bureau.\n",
    "\n",
    "Also, this way, you will get to compare how conventional neural networks compare to convolutional neural networks, that we will build in the next module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives for this Notebook    \n",
    "* Use the MNIST database for training various image processing systems\n",
    "* Build a neural network\n",
    "* Train and test the network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3>\n",
    "\n",
    "1. <a href=\"#Import-Keras-and-Packages\">Import Keras and Packages</a>      \n",
    "2. <a href=\"#Build-a-Neural-Network\">Build a Neural Network</a>     \n",
    "3. <a href=\"#Train-and-Test-the-Network\">Train and Test the Network</a>     \n",
    "\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by installing Keras and other necessary libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_cpu\n",
      "  Downloading tensorflow_cpu-2.13.1-cp38-cp38-win_amd64.whl.metadata (2.6 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow-cpu to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading tensorflow_cpu-2.13.0-cp38-cp38-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting tensorflow-intel==2.13.0 (from tensorflow_cpu)\n",
      "  Downloading tensorflow_intel-2.13.0-cp38-cp38-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading h5py-3.11.0-cp38-cp38-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow_cpu) (1.24.3)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow_cpu) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading protobuf-4.25.8-cp38-cp38-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow_cpu) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow_cpu) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading wrapt-1.17.2-cp38-cp38-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading grpcio-1.70.0-cp38-cp38-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp38-cp38-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow_cpu) (0.44.0)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading google_auth-2.40.2-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu) (2.32.3)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu) (8.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu) (3.21.0)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow_cpu)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading tensorflow_cpu-2.13.0-cp38-cp38-win_amd64.whl (2.0 kB)\n",
      "Downloading tensorflow_intel-2.13.0-cp38-cp38-win_amd64.whl (276.5 MB)\n",
      "   ---------------------------------------- 0.0/276.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/276.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/276.5 MB 9.8 MB/s eta 0:00:29\n",
      "    --------------------------------------- 4.2/276.5 MB 11.4 MB/s eta 0:00:24\n",
      "    --------------------------------------- 6.8/276.5 MB 10.2 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 9.4/276.5 MB 10.9 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 11.3/276.5 MB 11.2 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 13.6/276.5 MB 10.6 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 14.7/276.5 MB 9.8 MB/s eta 0:00:27\n",
      "   -- ------------------------------------- 15.7/276.5 MB 9.2 MB/s eta 0:00:29\n",
      "   -- ------------------------------------- 16.5/276.5 MB 8.7 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 17.6/276.5 MB 8.4 MB/s eta 0:00:31\n",
      "   -- ------------------------------------- 18.9/276.5 MB 8.0 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 19.9/276.5 MB 7.8 MB/s eta 0:00:33\n",
      "   --- ------------------------------------ 21.0/276.5 MB 7.6 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 22.0/276.5 MB 7.4 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 22.8/276.5 MB 7.1 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 23.6/276.5 MB 6.9 MB/s eta 0:00:37\n",
      "   --- ------------------------------------ 24.4/276.5 MB 6.8 MB/s eta 0:00:38\n",
      "   --- ------------------------------------ 25.4/276.5 MB 6.6 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 26.2/276.5 MB 6.5 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 27.0/276.5 MB 6.4 MB/s eta 0:00:40\n",
      "   ---- ----------------------------------- 27.8/276.5 MB 6.3 MB/s eta 0:00:40\n",
      "   ---- ----------------------------------- 28.8/276.5 MB 6.2 MB/s eta 0:00:41\n",
      "   ---- ----------------------------------- 29.6/276.5 MB 6.1 MB/s eta 0:00:41\n",
      "   ---- ----------------------------------- 30.7/276.5 MB 6.0 MB/s eta 0:00:41\n",
      "   ---- ----------------------------------- 31.5/276.5 MB 6.0 MB/s eta 0:00:42\n",
      "   ---- ----------------------------------- 32.5/276.5 MB 5.9 MB/s eta 0:00:42\n",
      "   ---- ----------------------------------- 33.6/276.5 MB 5.9 MB/s eta 0:00:42\n",
      "   ---- ----------------------------------- 34.3/276.5 MB 5.8 MB/s eta 0:00:42\n",
      "   ----- ---------------------------------- 35.4/276.5 MB 5.8 MB/s eta 0:00:42\n",
      "   ----- ---------------------------------- 36.4/276.5 MB 5.7 MB/s eta 0:00:42\n",
      "   ----- ---------------------------------- 37.0/276.5 MB 5.6 MB/s eta 0:00:43\n",
      "   ----- ---------------------------------- 37.2/276.5 MB 5.6 MB/s eta 0:00:43\n",
      "   ----- ---------------------------------- 37.7/276.5 MB 5.4 MB/s eta 0:00:45\n",
      "   ----- ---------------------------------- 38.0/276.5 MB 5.3 MB/s eta 0:00:45\n",
      "   ----- ---------------------------------- 38.3/276.5 MB 5.2 MB/s eta 0:00:46\n",
      "   ----- ---------------------------------- 38.8/276.5 MB 5.1 MB/s eta 0:00:47\n",
      "   ----- ---------------------------------- 39.1/276.5 MB 5.0 MB/s eta 0:00:48\n",
      "   ----- ---------------------------------- 39.6/276.5 MB 4.9 MB/s eta 0:00:48\n",
      "   ----- ---------------------------------- 40.1/276.5 MB 4.8 MB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 40.4/276.5 MB 4.8 MB/s eta 0:00:50\n",
      "   ----- ---------------------------------- 40.9/276.5 MB 4.7 MB/s eta 0:00:51\n",
      "   ----- ---------------------------------- 41.2/276.5 MB 4.7 MB/s eta 0:00:51\n",
      "   ------ --------------------------------- 41.7/276.5 MB 4.6 MB/s eta 0:00:52\n",
      "   ------ --------------------------------- 41.9/276.5 MB 4.5 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 41.9/276.5 MB 4.5 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 42.2/276.5 MB 4.4 MB/s eta 0:00:54\n",
      "   ------ --------------------------------- 42.5/276.5 MB 4.3 MB/s eta 0:00:55\n",
      "   ------ --------------------------------- 42.5/276.5 MB 4.3 MB/s eta 0:00:55\n",
      "   ------ --------------------------------- 42.7/276.5 MB 4.1 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 42.7/276.5 MB 4.1 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 42.7/276.5 MB 4.1 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 42.7/276.5 MB 4.1 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 42.7/276.5 MB 4.1 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 43.0/276.5 MB 3.8 MB/s eta 0:01:02\n",
      "   ------ --------------------------------- 43.0/276.5 MB 3.8 MB/s eta 0:01:02\n",
      "   ------ --------------------------------- 43.0/276.5 MB 3.8 MB/s eta 0:01:02\n",
      "   ------ --------------------------------- 43.3/276.5 MB 3.6 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 43.3/276.5 MB 3.6 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 43.5/276.5 MB 3.5 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 43.5/276.5 MB 3.5 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 43.5/276.5 MB 3.5 MB/s eta 0:01:07\n",
      "   ------ --------------------------------- 43.8/276.5 MB 3.4 MB/s eta 0:01:10\n",
      "   ------ --------------------------------- 43.8/276.5 MB 3.4 MB/s eta 0:01:10\n",
      "   ------ --------------------------------- 44.0/276.5 MB 3.3 MB/s eta 0:01:12\n",
      "   ------ --------------------------------- 44.0/276.5 MB 3.3 MB/s eta 0:01:12\n",
      "   ------ --------------------------------- 44.3/276.5 MB 3.2 MB/s eta 0:01:13\n",
      "   ------ --------------------------------- 44.6/276.5 MB 3.1 MB/s eta 0:01:15\n",
      "   ------ --------------------------------- 44.6/276.5 MB 3.1 MB/s eta 0:01:15\n",
      "   ------ --------------------------------- 44.8/276.5 MB 3.1 MB/s eta 0:01:16\n",
      "   ------ --------------------------------- 45.1/276.5 MB 3.0 MB/s eta 0:01:17\n",
      "   ------ --------------------------------- 45.1/276.5 MB 3.0 MB/s eta 0:01:17\n",
      "   ------ --------------------------------- 45.4/276.5 MB 3.0 MB/s eta 0:01:18\n",
      "   ------ --------------------------------- 45.6/276.5 MB 2.9 MB/s eta 0:01:19\n",
      "   ------ --------------------------------- 45.6/276.5 MB 2.9 MB/s eta 0:01:19\n",
      "   ------ --------------------------------- 45.9/276.5 MB 2.9 MB/s eta 0:01:20\n",
      "   ------ --------------------------------- 46.1/276.5 MB 2.9 MB/s eta 0:01:21\n",
      "   ------ --------------------------------- 46.1/276.5 MB 2.9 MB/s eta 0:01:21\n",
      "   ------ --------------------------------- 46.4/276.5 MB 2.8 MB/s eta 0:01:22\n",
      "   ------ --------------------------------- 46.7/276.5 MB 2.8 MB/s eta 0:01:22\n",
      "   ------ --------------------------------- 46.9/276.5 MB 2.8 MB/s eta 0:01:23\n",
      "   ------ --------------------------------- 47.2/276.5 MB 2.8 MB/s eta 0:01:24\n",
      "   ------ --------------------------------- 47.4/276.5 MB 2.7 MB/s eta 0:01:24\n",
      "   ------ --------------------------------- 47.7/276.5 MB 2.7 MB/s eta 0:01:25\n",
      "   ------ --------------------------------- 48.0/276.5 MB 2.7 MB/s eta 0:01:25\n",
      "   ------ --------------------------------- 48.2/276.5 MB 2.7 MB/s eta 0:01:26\n",
      "   ------- -------------------------------- 48.5/276.5 MB 2.7 MB/s eta 0:01:26\n",
      "   ------- -------------------------------- 48.8/276.5 MB 2.7 MB/s eta 0:01:26\n",
      "   ------- -------------------------------- 49.0/276.5 MB 2.6 MB/s eta 0:01:27\n",
      "   ------- -------------------------------- 49.5/276.5 MB 2.6 MB/s eta 0:01:27\n",
      "   ------- -------------------------------- 49.8/276.5 MB 2.6 MB/s eta 0:01:27\n",
      "   ------- -------------------------------- 50.1/276.5 MB 2.6 MB/s eta 0:01:27\n",
      "   ------- -------------------------------- 50.6/276.5 MB 2.6 MB/s eta 0:01:28\n",
      "   ------- -------------------------------- 50.9/276.5 MB 2.6 MB/s eta 0:01:28\n",
      "   ------- -------------------------------- 51.1/276.5 MB 2.6 MB/s eta 0:01:28\n",
      "   ------- -------------------------------- 51.6/276.5 MB 2.6 MB/s eta 0:01:28\n",
      "   ------- -------------------------------- 51.9/276.5 MB 2.6 MB/s eta 0:01:28\n",
      "   ------- -------------------------------- 52.2/276.5 MB 2.5 MB/s eta 0:01:29\n",
      "   ------- -------------------------------- 52.4/276.5 MB 2.5 MB/s eta 0:01:29\n",
      "   ------- -------------------------------- 53.0/276.5 MB 2.5 MB/s eta 0:01:29\n",
      "   ------- -------------------------------- 53.2/276.5 MB 2.5 MB/s eta 0:01:29\n",
      "   ------- -------------------------------- 53.5/276.5 MB 2.5 MB/s eta 0:01:29\n",
      "   ------- -------------------------------- 54.0/276.5 MB 2.5 MB/s eta 0:01:30\n",
      "   ------- -------------------------------- 54.3/276.5 MB 2.5 MB/s eta 0:01:30\n",
      "   ------- -------------------------------- 54.8/276.5 MB 2.5 MB/s eta 0:01:30\n",
      "   ------- -------------------------------- 55.1/276.5 MB 2.5 MB/s eta 0:01:30\n",
      "   -------- ------------------------------- 55.3/276.5 MB 2.5 MB/s eta 0:01:30\n",
      "   -------- ------------------------------- 55.6/276.5 MB 2.5 MB/s eta 0:01:30\n",
      "   -------- ------------------------------- 55.8/276.5 MB 2.5 MB/s eta 0:01:30\n",
      "   -------- ------------------------------- 56.4/276.5 MB 2.4 MB/s eta 0:01:31\n",
      "   -------- ------------------------------- 56.6/276.5 MB 2.4 MB/s eta 0:01:31\n",
      "   -------- ------------------------------- 56.9/276.5 MB 2.4 MB/s eta 0:01:31\n",
      "   -------- ------------------------------- 57.1/276.5 MB 2.4 MB/s eta 0:01:31\n",
      "   -------- ------------------------------- 57.4/276.5 MB 2.4 MB/s eta 0:01:31\n",
      "   -------- ------------------------------- 57.9/276.5 MB 2.4 MB/s eta 0:01:32\n",
      "   -------- ------------------------------- 58.2/276.5 MB 2.4 MB/s eta 0:01:32\n",
      "   -------- ------------------------------- 58.5/276.5 MB 2.4 MB/s eta 0:01:32\n",
      "   -------- ------------------------------- 59.0/276.5 MB 2.4 MB/s eta 0:01:32\n",
      "   -------- ------------------------------- 59.2/276.5 MB 2.4 MB/s eta 0:01:32\n",
      "   -------- ------------------------------- 59.5/276.5 MB 2.4 MB/s eta 0:01:32\n",
      "   -------- ------------------------------- 59.8/276.5 MB 2.4 MB/s eta 0:01:32\n",
      "   -------- ------------------------------- 60.0/276.5 MB 2.3 MB/s eta 0:01:33\n",
      "   -------- ------------------------------- 60.3/276.5 MB 2.3 MB/s eta 0:01:33\n",
      "   -------- ------------------------------- 60.6/276.5 MB 2.3 MB/s eta 0:01:33\n",
      "   -------- ------------------------------- 60.8/276.5 MB 2.3 MB/s eta 0:01:34\n",
      "   -------- ------------------------------- 61.1/276.5 MB 2.3 MB/s eta 0:01:34\n",
      "   -------- ------------------------------- 61.3/276.5 MB 2.3 MB/s eta 0:01:34\n",
      "   -------- ------------------------------- 61.6/276.5 MB 2.3 MB/s eta 0:01:34\n",
      "   -------- ------------------------------- 61.9/276.5 MB 2.3 MB/s eta 0:01:34\n",
      "   -------- ------------------------------- 62.1/276.5 MB 2.3 MB/s eta 0:01:35\n",
      "   --------- ------------------------------ 62.4/276.5 MB 2.3 MB/s eta 0:01:35\n",
      "   --------- ------------------------------ 62.9/276.5 MB 2.3 MB/s eta 0:01:35\n",
      "   --------- ------------------------------ 63.2/276.5 MB 2.3 MB/s eta 0:01:35\n",
      "   --------- ------------------------------ 63.4/276.5 MB 2.3 MB/s eta 0:01:35\n",
      "   --------- ------------------------------ 63.7/276.5 MB 2.3 MB/s eta 0:01:35\n",
      "   --------- ------------------------------ 64.2/276.5 MB 2.2 MB/s eta 0:01:35\n",
      "   --------- ------------------------------ 64.5/276.5 MB 2.2 MB/s eta 0:01:35\n",
      "   --------- ------------------------------ 65.0/276.5 MB 2.2 MB/s eta 0:01:35\n",
      "   --------- ------------------------------ 65.3/276.5 MB 2.2 MB/s eta 0:01:35\n",
      "   --------- ------------------------------ 65.8/276.5 MB 2.2 MB/s eta 0:01:35\n",
      "   --------- ------------------------------ 66.1/276.5 MB 2.2 MB/s eta 0:01:35\n",
      "   --------- ------------------------------ 66.6/276.5 MB 2.2 MB/s eta 0:01:35\n",
      "   --------- ------------------------------ 67.1/276.5 MB 2.2 MB/s eta 0:01:34\n",
      "   --------- ------------------------------ 67.6/276.5 MB 2.2 MB/s eta 0:01:36\n",
      "   --------- ------------------------------ 67.9/276.5 MB 2.1 MB/s eta 0:01:39\n",
      "   --------- ------------------------------ 68.4/276.5 MB 2.1 MB/s eta 0:01:41\n",
      "   --------- ------------------------------ 68.9/276.5 MB 2.0 MB/s eta 0:01:45\n",
      "   ---------- ----------------------------- 69.5/276.5 MB 1.9 MB/s eta 0:01:48\n",
      "   ---------- ----------------------------- 70.0/276.5 MB 1.9 MB/s eta 0:01:51\n",
      "   ---------- ----------------------------- 70.3/276.5 MB 1.9 MB/s eta 0:01:51\n",
      "   ---------- ----------------------------- 70.8/276.5 MB 1.8 MB/s eta 0:01:52\n",
      "   ---------- ----------------------------- 71.6/276.5 MB 1.8 MB/s eta 0:01:53\n",
      "   ---------- ----------------------------- 71.8/276.5 MB 1.8 MB/s eta 0:01:54\n",
      "   ---------- ----------------------------- 72.4/276.5 MB 1.8 MB/s eta 0:01:55\n",
      "   ---------- ----------------------------- 72.9/276.5 MB 1.8 MB/s eta 0:01:56\n",
      "   ---------- ----------------------------- 73.1/276.5 MB 1.7 MB/s eta 0:01:57\n",
      "   ---------- ----------------------------- 73.7/276.5 MB 1.7 MB/s eta 0:01:59\n",
      "   ---------- ----------------------------- 73.9/276.5 MB 1.7 MB/s eta 0:02:00\n",
      "   ---------- ----------------------------- 74.2/276.5 MB 1.7 MB/s eta 0:02:00\n",
      "   ---------- ----------------------------- 74.7/276.5 MB 1.7 MB/s eta 0:02:02\n",
      "   ---------- ----------------------------- 75.0/276.5 MB 1.7 MB/s eta 0:02:02\n",
      "   ---------- ----------------------------- 75.2/276.5 MB 1.6 MB/s eta 0:02:03\n",
      "   ---------- ----------------------------- 75.8/276.5 MB 1.6 MB/s eta 0:02:05\n",
      "   ---------- ----------------------------- 76.0/276.5 MB 1.6 MB/s eta 0:02:06\n",
      "   ----------- ---------------------------- 76.3/276.5 MB 1.6 MB/s eta 0:02:06\n",
      "   ----------- ---------------------------- 76.8/276.5 MB 1.6 MB/s eta 0:02:08\n",
      "   ----------- ---------------------------- 77.1/276.5 MB 1.5 MB/s eta 0:02:09\n",
      "   ----------- ---------------------------- 77.3/276.5 MB 1.5 MB/s eta 0:02:11\n",
      "   ----------- ---------------------------- 77.6/276.5 MB 1.5 MB/s eta 0:02:12\n",
      "   ----------- ---------------------------- 78.1/276.5 MB 1.5 MB/s eta 0:02:15\n",
      "   ----------- ---------------------------- 78.4/276.5 MB 1.5 MB/s eta 0:02:16\n",
      "   ----------- ---------------------------- 78.6/276.5 MB 1.5 MB/s eta 0:02:17\n",
      "   ----------- ---------------------------- 78.9/276.5 MB 1.4 MB/s eta 0:02:19\n",
      "   ----------- ---------------------------- 79.2/276.5 MB 1.4 MB/s eta 0:02:20\n",
      "   ----------- ---------------------------- 79.4/276.5 MB 1.4 MB/s eta 0:02:21\n",
      "   ----------- ---------------------------- 79.7/276.5 MB 1.4 MB/s eta 0:02:21\n",
      "   ----------- ---------------------------- 80.0/276.5 MB 1.4 MB/s eta 0:02:21\n",
      "   ----------- ---------------------------- 80.2/276.5 MB 1.4 MB/s eta 0:02:21\n",
      "   ----------- ---------------------------- 80.7/276.5 MB 1.4 MB/s eta 0:02:21\n",
      "   ----------- ---------------------------- 81.0/276.5 MB 1.4 MB/s eta 0:02:21\n",
      "   ----------- ---------------------------- 81.3/276.5 MB 1.4 MB/s eta 0:02:21\n",
      "   ----------- ---------------------------- 81.5/276.5 MB 1.4 MB/s eta 0:02:21\n",
      "   ----------- ---------------------------- 81.8/276.5 MB 1.4 MB/s eta 0:02:21\n",
      "   ----------- ---------------------------- 82.1/276.5 MB 1.4 MB/s eta 0:02:21\n",
      "   ----------- ---------------------------- 82.3/276.5 MB 1.4 MB/s eta 0:02:22\n",
      "   ----------- ---------------------------- 82.6/276.5 MB 1.4 MB/s eta 0:02:23\n",
      "   ----------- ---------------------------- 82.6/276.5 MB 1.4 MB/s eta 0:02:23\n",
      "   ----------- ---------------------------- 82.8/276.5 MB 1.4 MB/s eta 0:02:23\n",
      "   ----------- ---------------------------- 82.8/276.5 MB 1.4 MB/s eta 0:02:23\n",
      "   ------------ --------------------------- 83.1/276.5 MB 1.4 MB/s eta 0:02:23\n",
      "   ------------ --------------------------- 83.4/276.5 MB 1.4 MB/s eta 0:02:22\n",
      "   ------------ --------------------------- 83.4/276.5 MB 1.4 MB/s eta 0:02:22\n",
      "   ------------ --------------------------- 83.6/276.5 MB 1.4 MB/s eta 0:02:19\n",
      "   ------------ --------------------------- 83.9/276.5 MB 1.4 MB/s eta 0:02:19\n",
      "   ------------ --------------------------- 84.1/276.5 MB 1.4 MB/s eta 0:02:19\n",
      "   ------------ --------------------------- 84.1/276.5 MB 1.4 MB/s eta 0:02:19\n",
      "   ------------ --------------------------- 84.4/276.5 MB 1.4 MB/s eta 0:02:19\n",
      "   ------------ --------------------------- 84.7/276.5 MB 1.4 MB/s eta 0:02:17\n",
      "   ------------ --------------------------- 84.9/276.5 MB 1.4 MB/s eta 0:02:17\n",
      "   ------------ --------------------------- 85.2/276.5 MB 1.4 MB/s eta 0:02:16\n",
      "   ------------ --------------------------- 85.5/276.5 MB 1.4 MB/s eta 0:02:16\n",
      "   ------------ --------------------------- 85.7/276.5 MB 1.4 MB/s eta 0:02:16\n",
      "   ------------ --------------------------- 86.0/276.5 MB 1.4 MB/s eta 0:02:14\n",
      "   ------------ --------------------------- 86.2/276.5 MB 1.4 MB/s eta 0:02:14\n",
      "   ------------ --------------------------- 86.8/276.5 MB 1.4 MB/s eta 0:02:12\n",
      "   ------------ --------------------------- 87.0/276.5 MB 1.4 MB/s eta 0:02:12\n",
      "   ------------ --------------------------- 87.3/276.5 MB 1.5 MB/s eta 0:02:11\n",
      "   ------------ --------------------------- 87.6/276.5 MB 1.5 MB/s eta 0:02:11\n",
      "   ------------ --------------------------- 88.1/276.5 MB 1.5 MB/s eta 0:02:09\n",
      "   ------------ --------------------------- 88.3/276.5 MB 1.5 MB/s eta 0:02:09\n",
      "   ------------ --------------------------- 88.9/276.5 MB 1.5 MB/s eta 0:02:08\n",
      "   ------------ --------------------------- 89.1/276.5 MB 1.5 MB/s eta 0:02:07\n",
      "   ------------ --------------------------- 89.4/276.5 MB 1.5 MB/s eta 0:02:07\n",
      "   ------------ --------------------------- 89.7/276.5 MB 1.5 MB/s eta 0:02:06\n",
      "   ------------- -------------------------- 89.9/276.5 MB 1.5 MB/s eta 0:02:06\n",
      "   ------------- -------------------------- 90.4/276.5 MB 1.5 MB/s eta 0:02:04\n",
      "   ------------- -------------------------- 90.7/276.5 MB 1.5 MB/s eta 0:02:04\n",
      "   ------------- -------------------------- 91.0/276.5 MB 1.5 MB/s eta 0:02:04\n",
      "   ------------- -------------------------- 91.5/276.5 MB 1.5 MB/s eta 0:02:03\n",
      "   ------------- -------------------------- 91.8/276.5 MB 1.5 MB/s eta 0:02:02\n",
      "   ------------- -------------------------- 92.0/276.5 MB 1.5 MB/s eta 0:02:02\n",
      "   ------------- -------------------------- 92.5/276.5 MB 1.5 MB/s eta 0:02:01\n",
      "   ------------- -------------------------- 92.8/276.5 MB 1.5 MB/s eta 0:02:01\n",
      "   ------------- -------------------------- 93.3/276.5 MB 1.5 MB/s eta 0:01:59\n",
      "   ------------- -------------------------- 93.6/276.5 MB 1.5 MB/s eta 0:01:59\n",
      "   ------------- -------------------------- 94.1/276.5 MB 1.5 MB/s eta 0:01:58\n",
      "   ------------- -------------------------- 94.4/276.5 MB 1.6 MB/s eta 0:01:58\n",
      "   ------------- -------------------------- 94.6/276.5 MB 1.6 MB/s eta 0:01:58\n",
      "   ------------- -------------------------- 95.2/276.5 MB 1.6 MB/s eta 0:01:57\n",
      "   ------------- -------------------------- 95.4/276.5 MB 1.6 MB/s eta 0:01:57\n",
      "   ------------- -------------------------- 95.7/276.5 MB 1.6 MB/s eta 0:01:57\n",
      "   ------------- -------------------------- 96.2/276.5 MB 1.6 MB/s eta 0:01:56\n",
      "   ------------- -------------------------- 96.5/276.5 MB 1.6 MB/s eta 0:01:56\n",
      "   ------------- -------------------------- 96.7/276.5 MB 1.6 MB/s eta 0:01:56\n",
      "   -------------- ------------------------- 97.3/276.5 MB 1.6 MB/s eta 0:01:56\n",
      "   -------------- ------------------------- 97.5/276.5 MB 1.6 MB/s eta 0:01:55\n",
      "   -------------- ------------------------- 98.0/276.5 MB 1.6 MB/s eta 0:01:55\n",
      "   -------------- ------------------------- 98.3/276.5 MB 1.6 MB/s eta 0:01:55\n",
      "   -------------- ------------------------- 98.6/276.5 MB 1.6 MB/s eta 0:01:54\n",
      "   -------------- ------------------------- 98.8/276.5 MB 1.6 MB/s eta 0:01:54\n",
      "   -------------- ------------------------- 99.1/276.5 MB 1.6 MB/s eta 0:01:54\n",
      "   -------------- ------------------------- 99.4/276.5 MB 1.6 MB/s eta 0:01:55\n",
      "   -------------- ------------------------- 99.6/276.5 MB 1.5 MB/s eta 0:01:55\n",
      "   -------------- ------------------------- 99.9/276.5 MB 1.5 MB/s eta 0:01:55\n",
      "   -------------- ------------------------- 100.1/276.5 MB 1.5 MB/s eta 0:01:55\n",
      "   -------------- ------------------------- 100.4/276.5 MB 1.5 MB/s eta 0:01:55\n",
      "   -------------- ------------------------- 100.7/276.5 MB 1.5 MB/s eta 0:01:55\n",
      "   -------------- ------------------------- 100.9/276.5 MB 1.5 MB/s eta 0:01:55\n",
      "   -------------- ------------------------- 101.4/276.5 MB 1.5 MB/s eta 0:01:55\n",
      "   -------------- ------------------------- 101.7/276.5 MB 1.5 MB/s eta 0:01:55\n",
      "   -------------- ------------------------- 102.0/276.5 MB 1.5 MB/s eta 0:01:54\n",
      "   -------------- ------------------------- 102.2/276.5 MB 1.5 MB/s eta 0:01:54\n",
      "   -------------- ------------------------- 102.5/276.5 MB 1.5 MB/s eta 0:01:54\n",
      "   -------------- ------------------------- 102.8/276.5 MB 1.5 MB/s eta 0:01:54\n",
      "   -------------- ------------------------- 103.0/276.5 MB 1.5 MB/s eta 0:01:54\n",
      "   -------------- ------------------------- 103.3/276.5 MB 1.5 MB/s eta 0:01:54\n",
      "   -------------- ------------------------- 103.5/276.5 MB 1.5 MB/s eta 0:01:54\n",
      "   --------------- ------------------------ 103.8/276.5 MB 1.5 MB/s eta 0:01:54\n",
      "   --------------- ------------------------ 104.3/276.5 MB 1.5 MB/s eta 0:01:54\n",
      "   --------------- ------------------------ 104.6/276.5 MB 1.5 MB/s eta 0:01:54\n",
      "   --------------- ------------------------ 104.9/276.5 MB 1.5 MB/s eta 0:01:54\n",
      "   --------------- ------------------------ 104.9/276.5 MB 1.5 MB/s eta 0:01:54\n",
      "   --------------- ------------------------ 105.1/276.5 MB 1.5 MB/s eta 0:01:54\n",
      "   --------------- ------------------------ 105.4/276.5 MB 1.5 MB/s eta 0:01:54\n",
      "   --------------- ------------------------ 105.6/276.5 MB 1.5 MB/s eta 0:01:53\n",
      "   --------------- ------------------------ 105.9/276.5 MB 1.5 MB/s eta 0:01:53\n",
      "   --------------- ------------------------ 106.2/276.5 MB 1.5 MB/s eta 0:01:53\n",
      "   --------------- ------------------------ 106.4/276.5 MB 1.5 MB/s eta 0:01:53\n",
      "   --------------- ------------------------ 106.7/276.5 MB 1.5 MB/s eta 0:01:52\n",
      "   --------------- ------------------------ 107.0/276.5 MB 1.5 MB/s eta 0:01:52\n",
      "   --------------- ------------------------ 107.2/276.5 MB 1.5 MB/s eta 0:01:52\n",
      "   --------------- ------------------------ 107.7/276.5 MB 1.5 MB/s eta 0:01:52\n",
      "   --------------- ------------------------ 108.0/276.5 MB 1.5 MB/s eta 0:01:51\n",
      "   --------------- ------------------------ 108.3/276.5 MB 1.5 MB/s eta 0:01:51\n",
      "   --------------- ------------------------ 108.5/276.5 MB 1.5 MB/s eta 0:01:51\n",
      "   --------------- ------------------------ 109.1/276.5 MB 1.5 MB/s eta 0:01:51\n",
      "   --------------- ------------------------ 109.3/276.5 MB 1.5 MB/s eta 0:01:50\n",
      "   --------------- ------------------------ 109.8/276.5 MB 1.5 MB/s eta 0:01:50\n",
      "   --------------- ------------------------ 110.1/276.5 MB 1.5 MB/s eta 0:01:50\n",
      "   ---------------- ----------------------- 110.6/276.5 MB 1.5 MB/s eta 0:01:49\n",
      "   ---------------- ----------------------- 110.9/276.5 MB 1.5 MB/s eta 0:01:49\n",
      "   ---------------- ----------------------- 111.4/276.5 MB 1.5 MB/s eta 0:01:49\n",
      "   ---------------- ----------------------- 111.7/276.5 MB 1.5 MB/s eta 0:01:49\n",
      "   ---------------- ----------------------- 112.2/276.5 MB 1.5 MB/s eta 0:01:48\n",
      "   ---------------- ----------------------- 112.7/276.5 MB 1.5 MB/s eta 0:01:48\n",
      "   ---------------- ----------------------- 113.0/276.5 MB 1.5 MB/s eta 0:01:48\n",
      "   ---------------- ----------------------- 113.5/276.5 MB 1.5 MB/s eta 0:01:48\n",
      "   ---------------- ----------------------- 114.0/276.5 MB 1.5 MB/s eta 0:01:47\n",
      "   ---------------- ----------------------- 114.6/276.5 MB 1.5 MB/s eta 0:01:47\n",
      "   ---------------- ----------------------- 115.1/276.5 MB 1.5 MB/s eta 0:01:46\n",
      "   ---------------- ----------------------- 115.6/276.5 MB 1.5 MB/s eta 0:01:46\n",
      "   ---------------- ----------------------- 116.1/276.5 MB 1.5 MB/s eta 0:01:46\n",
      "   ---------------- ----------------------- 116.4/276.5 MB 1.5 MB/s eta 0:01:46\n",
      "   ---------------- ----------------------- 116.9/276.5 MB 1.5 MB/s eta 0:01:46\n",
      "   ---------------- ----------------------- 117.4/276.5 MB 1.5 MB/s eta 0:01:45\n",
      "   ----------------- ---------------------- 118.0/276.5 MB 1.5 MB/s eta 0:01:45\n",
      "   ----------------- ---------------------- 118.5/276.5 MB 1.5 MB/s eta 0:01:44\n",
      "   ----------------- ---------------------- 119.3/276.5 MB 1.5 MB/s eta 0:01:43\n",
      "   ----------------- ---------------------- 119.8/276.5 MB 1.5 MB/s eta 0:01:42\n",
      "   ----------------- ---------------------- 120.3/276.5 MB 1.5 MB/s eta 0:01:41\n",
      "   ----------------- ---------------------- 120.8/276.5 MB 1.6 MB/s eta 0:01:40\n",
      "   ----------------- ---------------------- 121.6/276.5 MB 1.6 MB/s eta 0:01:39\n",
      "   ----------------- ---------------------- 122.2/276.5 MB 1.6 MB/s eta 0:01:38\n",
      "   ----------------- ---------------------- 122.9/276.5 MB 1.6 MB/s eta 0:01:37\n",
      "   ----------------- ---------------------- 123.5/276.5 MB 1.6 MB/s eta 0:01:36\n",
      "   ----------------- ---------------------- 123.7/276.5 MB 1.6 MB/s eta 0:01:36\n",
      "   ----------------- ---------------------- 123.7/276.5 MB 1.6 MB/s eta 0:01:36\n",
      "   ----------------- ---------------------- 124.0/276.5 MB 1.6 MB/s eta 0:01:37\n",
      "   ----------------- ---------------------- 124.3/276.5 MB 1.6 MB/s eta 0:01:37\n",
      "   ------------------ --------------------- 124.8/276.5 MB 1.6 MB/s eta 0:01:36\n",
      "   ------------------ --------------------- 125.0/276.5 MB 1.6 MB/s eta 0:01:36\n",
      "   ------------------ --------------------- 125.3/276.5 MB 1.6 MB/s eta 0:01:36\n",
      "   ------------------ --------------------- 125.3/276.5 MB 1.6 MB/s eta 0:01:36\n",
      "   ------------------ --------------------- 125.8/276.5 MB 1.6 MB/s eta 0:01:36\n",
      "   ------------------ --------------------- 126.1/276.5 MB 1.6 MB/s eta 0:01:36\n",
      "   ------------------ --------------------- 126.1/276.5 MB 1.6 MB/s eta 0:01:36\n",
      "   ------------------ --------------------- 126.6/276.5 MB 1.6 MB/s eta 0:01:36\n",
      "   ------------------ --------------------- 126.6/276.5 MB 1.6 MB/s eta 0:01:36\n",
      "   ------------------ --------------------- 127.1/276.5 MB 1.6 MB/s eta 0:01:35\n",
      "   ------------------ --------------------- 127.7/276.5 MB 1.6 MB/s eta 0:01:35\n",
      "   ------------------ --------------------- 129.8/276.5 MB 1.6 MB/s eta 0:01:30\n",
      "   ------------------- -------------------- 131.9/276.5 MB 1.7 MB/s eta 0:01:26\n",
      "   ------------------- -------------------- 134.2/276.5 MB 1.8 MB/s eta 0:01:21\n",
      "   ------------------- -------------------- 136.1/276.5 MB 1.8 MB/s eta 0:01:18\n",
      "   ------------------- -------------------- 136.1/276.5 MB 1.8 MB/s eta 0:01:18\n",
      "   ------------------- -------------------- 136.8/276.5 MB 1.8 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 136.8/276.5 MB 1.8 MB/s eta 0:01:17\n",
      "   ------------------- -------------------- 137.4/276.5 MB 1.8 MB/s eta 0:01:16\n",
      "   ------------------- -------------------- 137.9/276.5 MB 1.9 MB/s eta 0:01:15\n",
      "   -------------------- ------------------- 139.7/276.5 MB 1.9 MB/s eta 0:01:13\n",
      "   -------------------- ------------------- 142.3/276.5 MB 2.0 MB/s eta 0:01:08\n",
      "   -------------------- ------------------- 143.9/276.5 MB 2.0 MB/s eta 0:01:06\n",
      "   --------------------- ------------------ 147.1/276.5 MB 2.1 MB/s eta 0:01:01\n",
      "   --------------------- ------------------ 148.6/276.5 MB 2.2 MB/s eta 0:00:59\n",
      "   --------------------- ------------------ 150.5/276.5 MB 2.2 MB/s eta 0:00:57\n",
      "   --------------------- ------------------ 152.0/276.5 MB 2.3 MB/s eta 0:00:55\n",
      "   ---------------------- ----------------- 153.4/276.5 MB 2.3 MB/s eta 0:00:54\n",
      "   ---------------------- ----------------- 154.9/276.5 MB 2.4 MB/s eta 0:00:52\n",
      "   ---------------------- ----------------- 156.8/276.5 MB 2.4 MB/s eta 0:00:50\n",
      "   ---------------------- ----------------- 158.6/276.5 MB 2.5 MB/s eta 0:00:48\n",
      "   ----------------------- ---------------- 160.4/276.5 MB 2.5 MB/s eta 0:00:47\n",
      "   ----------------------- ---------------- 162.3/276.5 MB 2.6 MB/s eta 0:00:45\n",
      "   ----------------------- ---------------- 164.1/276.5 MB 2.6 MB/s eta 0:00:43\n",
      "   ------------------------ --------------- 165.9/276.5 MB 2.7 MB/s eta 0:00:42\n",
      "   ------------------------ --------------- 167.8/276.5 MB 2.7 MB/s eta 0:00:40\n",
      "   ------------------------ --------------- 169.9/276.5 MB 2.8 MB/s eta 0:00:39\n",
      "   ------------------------ --------------- 171.4/276.5 MB 2.8 MB/s eta 0:00:38\n",
      "   ------------------------- -------------- 173.0/276.5 MB 2.9 MB/s eta 0:00:37\n",
      "   ------------------------- -------------- 174.3/276.5 MB 2.9 MB/s eta 0:00:36\n",
      "   ------------------------- -------------- 175.9/276.5 MB 2.9 MB/s eta 0:00:35\n",
      "   ------------------------- -------------- 177.2/276.5 MB 3.0 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 178.5/276.5 MB 3.0 MB/s eta 0:00:33\n",
      "   -------------------------- ------------- 179.8/276.5 MB 3.0 MB/s eta 0:00:32\n",
      "   -------------------------- ------------- 180.9/276.5 MB 3.1 MB/s eta 0:00:32\n",
      "   -------------------------- ------------- 181.9/276.5 MB 3.1 MB/s eta 0:00:31\n",
      "   -------------------------- ------------- 183.2/276.5 MB 3.1 MB/s eta 0:00:30\n",
      "   -------------------------- ------------- 184.3/276.5 MB 3.2 MB/s eta 0:00:30\n",
      "   -------------------------- ------------- 185.6/276.5 MB 3.2 MB/s eta 0:00:29\n",
      "   --------------------------- ------------ 186.6/276.5 MB 3.2 MB/s eta 0:00:29\n",
      "   --------------------------- ------------ 188.0/276.5 MB 3.2 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 189.3/276.5 MB 3.3 MB/s eta 0:00:27\n",
      "   --------------------------- ------------ 190.3/276.5 MB 3.3 MB/s eta 0:00:27\n",
      "   --------------------------- ------------ 191.6/276.5 MB 3.3 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 192.7/276.5 MB 3.3 MB/s eta 0:00:26\n",
      "   ---------------------------- ----------- 193.7/276.5 MB 3.4 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 195.0/276.5 MB 3.4 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 196.3/276.5 MB 3.4 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 197.7/276.5 MB 3.5 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 198.7/276.5 MB 3.5 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 200.0/276.5 MB 3.5 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 201.3/276.5 MB 3.5 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 202.6/276.5 MB 3.6 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 203.9/276.5 MB 3.6 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 205.3/276.5 MB 3.6 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 206.6/276.5 MB 3.7 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 207.9/276.5 MB 3.7 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 208.9/276.5 MB 3.7 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 210.0/276.5 MB 3.7 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 210.8/276.5 MB 3.8 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 211.6/276.5 MB 3.8 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 212.1/276.5 MB 3.8 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 212.9/276.5 MB 3.8 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 213.4/276.5 MB 3.8 MB/s eta 0:00:17\n",
      "   ------------------------------ --------- 213.9/276.5 MB 3.8 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 214.7/276.5 MB 3.8 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 215.2/276.5 MB 3.9 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 216.0/276.5 MB 3.9 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 217.1/276.5 MB 3.9 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 217.8/276.5 MB 3.9 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 218.6/276.5 MB 3.9 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 219.4/276.5 MB 3.9 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 219.9/276.5 MB 4.0 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 220.7/276.5 MB 4.0 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 221.5/276.5 MB 4.0 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 222.3/276.5 MB 4.0 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 223.1/276.5 MB 4.0 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 223.9/276.5 MB 4.0 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 224.7/276.5 MB 4.1 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 225.7/276.5 MB 4.1 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 226.5/276.5 MB 4.1 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 227.3/276.5 MB 4.1 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 228.1/276.5 MB 4.1 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 229.1/276.5 MB 4.2 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 229.9/276.5 MB 4.2 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 230.9/276.5 MB 4.2 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 231.7/276.5 MB 4.2 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 232.8/276.5 MB 4.2 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 233.6/276.5 MB 4.3 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 234.6/276.5 MB 4.3 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 235.7/276.5 MB 4.3 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 236.5/276.5 MB 4.3 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 237.0/276.5 MB 4.3 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 238.0/276.5 MB 4.4 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 238.8/276.5 MB 4.4 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 239.6/276.5 MB 4.4 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 240.4/276.5 MB 4.4 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 241.2/276.5 MB 4.4 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 242.0/276.5 MB 4.4 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 242.7/276.5 MB 4.4 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 243.8/276.5 MB 4.5 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 244.6/276.5 MB 4.5 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 245.4/276.5 MB 4.5 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 246.4/276.5 MB 4.5 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 247.5/276.5 MB 4.5 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 248.3/276.5 MB 4.6 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 249.0/276.5 MB 4.6 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 250.1/276.5 MB 4.6 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 251.1/276.5 MB 4.6 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 251.9/276.5 MB 4.6 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 253.0/276.5 MB 4.6 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 254.0/276.5 MB 4.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 254.8/276.5 MB 4.7 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 255.9/276.5 MB 4.7 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 256.9/276.5 MB 4.7 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 257.9/276.5 MB 4.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 259.0/276.5 MB 4.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 259.8/276.5 MB 4.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 260.8/276.5 MB 4.8 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 261.9/276.5 MB 4.8 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 262.7/276.5 MB 4.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 263.7/276.5 MB 4.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 264.8/276.5 MB 4.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 265.6/276.5 MB 4.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 266.3/276.5 MB 4.8 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 267.4/276.5 MB 4.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 268.4/276.5 MB 4.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 269.5/276.5 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  270.5/276.5 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  271.6/276.5 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  272.6/276.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  273.4/276.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  274.2/276.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  275.3/276.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  275.8/276.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  276.3/276.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  276.3/276.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 276.5/276.5 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.70.0-cp38-cp38-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.5/4.3 MB 3.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.0/4.3 MB 3.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.8/4.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.6/4.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.1/4.3 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.9/4.3 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading h5py-3.11.0-cp38-cp38-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/3.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.3/3.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.8/3.0 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.6/3.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/26.4 MB 4.2 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 1.3/26.4 MB 3.7 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 2.1/26.4 MB 3.7 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.9/26.4 MB 3.6 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 3.4/26.4 MB 3.7 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 4.2/26.4 MB 3.5 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 4.7/26.4 MB 3.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 5.2/26.4 MB 3.3 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 6.0/26.4 MB 3.3 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 6.8/26.4 MB 3.3 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 7.3/26.4 MB 3.3 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 8.1/26.4 MB 3.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 8.9/26.4 MB 3.3 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 9.4/26.4 MB 3.3 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 10.2/26.4 MB 3.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 11.0/26.4 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 11.8/26.4 MB 3.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 12.3/26.4 MB 3.3 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 12.6/26.4 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 13.1/26.4 MB 3.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 13.9/26.4 MB 3.1 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 14.4/26.4 MB 3.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 15.2/26.4 MB 3.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 15.7/26.4 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 16.3/26.4 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 17.0/26.4 MB 3.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.6/26.4 MB 3.1 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 18.4/26.4 MB 3.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 18.9/26.4 MB 3.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 19.7/26.4 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 20.2/26.4 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 21.0/26.4 MB 3.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 21.5/26.4 MB 3.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 22.0/26.4 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 22.8/26.4 MB 3.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 23.6/26.4 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.1/26.4 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.9/26.4 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.7/26.4 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-4.25.8-cp38-cp38-win_amd64.whl (413 kB)\n",
      "Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/5.6 MB 2.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.6/5.6 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.4/5.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.1/5.6 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.6 MB 3.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.7/5.6 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 0.8/1.5 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Downloading wrapt-1.17.2-cp38-cp38-win_amd64.whl (38 kB)\n",
      "Downloading google_auth-2.40.2-py2.py3-none-any.whl (216 kB)\n",
      "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, oauthlib, keras, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow_cpu\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "Successfully installed absl-py-2.3.0 astunparse-1.6.3 cachetools-5.5.2 flatbuffers-25.2.10 gast-0.4.0 google-auth-2.40.2 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.70.0 h5py-3.11.0 keras-2.13.1 libclang-18.1.1 markdown-3.7 oauthlib-3.2.2 opt-einsum-3.4.0 protobuf-4.25.8 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-oauthlib-2.0.0 rsa-4.9.1 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-estimator-2.13.0 tensorflow-intel-2.13.0 tensorflow-io-gcs-filesystem-0.31.0 tensorflow_cpu-2.13.0 termcolor-2.4.0 typing-extensions-4.5.0 werkzeug-3.0.6 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\envs\\ml_learning\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "==== All required libraries are installed =====\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow_cpu\n",
    "%pip install matplotlib\n",
    "\n",
    "print(\"==== All required libraries are installed =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppress the tensorflow warning messages\n",
    "We use the following code to  suppress the warning messages due to use of CPU architechture for tensoflow.\n",
    "\n",
    "You may want to **comment out** these lines if you are using the GPU architechture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Keras and Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries. \n",
    "There might be some warning messages related to floating point round off errors and lack of GPU and other compiler related options. You can ignore these warnings and proceed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are dealing we images, let's also import the Matplotlib scripting layer in order to view the images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras library conveniently includes the MNIST dataset as part of its API. You can check other datasets within the Keras library [here](https://keras.io/datasets/). \n",
    "\n",
    "So, let's load the MNIST dataset from the Keras library. The dataset is readily divided into a training set and a test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# import the data\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# read the data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm the number of images in each set. According to the dataset's documentation, we should have 60000 images in X_train and 10000 images in the X_test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first number in the output tuple is the number of images, and the other two numbers are the size of the images in datset. So, each image is 28 pixels by 28 pixels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the first image in the training set using Matplotlib's scripting layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2747edc2880>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With conventional neural networks, we cannot feed in the image as input as is. So we need to flatten the images into one-dimensional vectors, each of size 1 x (28 x 28) = 1 x 784.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten images into one-dimensional vector\n",
    "\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2] # find size of one-dimensional vector\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32') # flatten training images\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32') # flatten test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since pixel values can range from 0 to 255, let's normalize the vectors to be between 0 and 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, before we start building our model, remember that for classification we need to divide our target variable into categories. We use the to_categorical function from the Keras Utilities package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1]\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define classification model\n",
    "def classification_model():\n",
    "    # create model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(num_pixels,)))\n",
    "    model.add(Dense(num_pixels, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 12s - loss: 0.1877 - accuracy: 0.9432 - val_loss: 0.0910 - val_accuracy: 0.9699 - 12s/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "1875/1875 - 15s - loss: 0.0788 - accuracy: 0.9751 - val_loss: 0.0691 - val_accuracy: 0.9780 - 15s/epoch - 8ms/step\n",
      "Epoch 3/10\n",
      "1875/1875 - 15s - loss: 0.0516 - accuracy: 0.9842 - val_loss: 0.0669 - val_accuracy: 0.9803 - 15s/epoch - 8ms/step\n",
      "Epoch 4/10\n",
      "1875/1875 - 15s - loss: 0.0398 - accuracy: 0.9870 - val_loss: 0.0793 - val_accuracy: 0.9752 - 15s/epoch - 8ms/step\n",
      "Epoch 5/10\n",
      "1875/1875 - 10s - loss: 0.0318 - accuracy: 0.9897 - val_loss: 0.0718 - val_accuracy: 0.9797 - 10s/epoch - 5ms/step\n",
      "Epoch 6/10\n",
      "1875/1875 - 9s - loss: 0.0274 - accuracy: 0.9912 - val_loss: 0.0682 - val_accuracy: 0.9821 - 9s/epoch - 5ms/step\n",
      "Epoch 7/10\n",
      "1875/1875 - 9s - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.0937 - val_accuracy: 0.9777 - 9s/epoch - 5ms/step\n",
      "Epoch 8/10\n",
      "1875/1875 - 9s - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.0971 - val_accuracy: 0.9794 - 9s/epoch - 5ms/step\n",
      "Epoch 9/10\n",
      "1875/1875 - 9s - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.0930 - val_accuracy: 0.9799 - 9s/epoch - 5ms/step\n",
      "Epoch 10/10\n",
      "1875/1875 - 9s - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.0858 - val_accuracy: 0.9802 - 9s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = classification_model()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the accuracy and the corresponding error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9801999926567078% \n",
      " Error: 0.019800007343292236\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}% \\n Error: {}'.format(scores[1], 1 - scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just running 10 epochs could actually take over 20 minutes. But enjoy the results as they are getting generated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, you cannot afford to retrain your model everytime you want to use it, especially if you are limited on computational resources and training your model can take a long time. Therefore, with the Keras library, you can save your model after training. To do that, we use the save method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classification_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our model contains multidimensional arrays of data, then models are usually saved as .keras files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are ready to use your model again, you use the load_model function from <strong>keras.saving</strong>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = keras.saving.load_model('classification_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Practice Exercise 1</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a neural network model with 6 dense layers and compare its accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 10s - loss: 0.2181 - accuracy: 0.9349 - val_loss: 0.1322 - val_accuracy: 0.9584 - 10s/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "1875/1875 - 10s - loss: 0.0998 - accuracy: 0.9701 - val_loss: 0.0899 - val_accuracy: 0.9760 - 10s/epoch - 5ms/step\n",
      "Epoch 3/10\n",
      "1875/1875 - 10s - loss: 0.0713 - accuracy: 0.9789 - val_loss: 0.0734 - val_accuracy: 0.9777 - 10s/epoch - 5ms/step\n",
      "Epoch 4/10\n",
      "1875/1875 - 10s - loss: 0.0570 - accuracy: 0.9834 - val_loss: 0.1002 - val_accuracy: 0.9718 - 10s/epoch - 5ms/step\n",
      "Epoch 5/10\n",
      "1875/1875 - 10s - loss: 0.0471 - accuracy: 0.9862 - val_loss: 0.0871 - val_accuracy: 0.9769 - 10s/epoch - 5ms/step\n",
      "Epoch 6/10\n",
      "1875/1875 - 9s - loss: 0.0391 - accuracy: 0.9883 - val_loss: 0.0918 - val_accuracy: 0.9766 - 9s/epoch - 5ms/step\n",
      "Epoch 7/10\n",
      "1875/1875 - 10s - loss: 0.0351 - accuracy: 0.9897 - val_loss: 0.0914 - val_accuracy: 0.9790 - 10s/epoch - 5ms/step\n",
      "Epoch 8/10\n",
      "1875/1875 - 10s - loss: 0.0293 - accuracy: 0.9913 - val_loss: 0.0930 - val_accuracy: 0.9795 - 10s/epoch - 5ms/step\n",
      "Epoch 9/10\n",
      "1875/1875 - 10s - loss: 0.0268 - accuracy: 0.9927 - val_loss: 0.1006 - val_accuracy: 0.9788 - 10s/epoch - 5ms/step\n",
      "Epoch 10/10\n",
      "1875/1875 - 10s - loss: 0.0245 - accuracy: 0.9926 - val_loss: 0.1153 - val_accuracy: 0.9734 - 10s/epoch - 5ms/step\n",
      "Accuracy_3_layers: 0.9801999926567078% \n",
      " Accuracy_6_layers: 0.9733999967575073\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "def classification_model_6layers():\n",
    "    # create model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(num_pixels,)))\n",
    "    model.add(Dense(num_pixels, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# build the model\n",
    "model_6layers = classification_model_6layers()\n",
    "\n",
    "# fit the model\n",
    "model_6layers.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores_6layers = model_6layers.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Accuracy_3_layers: {}% \\n Accuracy_6_layers: {}'.format(scores[1], scores_6layers[1]))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Practice Exercise 2</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load the the earlier saved model, train it further for 10 more epochs and check the accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained model loaded successufully\n",
      "Epoch 1/10\n",
      "1875/1875 - 9s - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.1128 - val_accuracy: 0.9794 - 9s/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "1875/1875 - 9s - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.1112 - val_accuracy: 0.9803 - 9s/epoch - 5ms/step\n",
      "Epoch 3/10\n",
      "1875/1875 - 9s - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.1087 - val_accuracy: 0.9790 - 9s/epoch - 5ms/step\n",
      "Epoch 4/10\n",
      "1875/1875 - 9s - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.1189 - val_accuracy: 0.9818 - 9s/epoch - 5ms/step\n",
      "Epoch 5/10\n",
      "1875/1875 - 9s - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.1228 - val_accuracy: 0.9798 - 9s/epoch - 5ms/step\n",
      "Epoch 6/10\n",
      "1875/1875 - 9s - loss: 0.0128 - accuracy: 0.9962 - val_loss: 0.0972 - val_accuracy: 0.9846 - 9s/epoch - 5ms/step\n",
      "Epoch 7/10\n",
      "1875/1875 - 10s - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.1366 - val_accuracy: 0.9802 - 10s/epoch - 5ms/step\n",
      "Epoch 8/10\n",
      "1875/1875 - 9s - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.1095 - val_accuracy: 0.9811 - 9s/epoch - 5ms/step\n",
      "Epoch 9/10\n",
      "1875/1875 - 9s - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.1317 - val_accuracy: 0.9800 - 9s/epoch - 5ms/step\n",
      "Epoch 10/10\n",
      "1875/1875 - 9s - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.1209 - val_accuracy: 0.9807 - 9s/epoch - 5ms/step\n",
      "Accuracy_10_epochs: 0.9801999926567078% \n",
      " Accuracy_20_epochs: 0.9807000160217285\n"
     ]
    }
   ],
   "source": [
    "#load the saved model\n",
    "pretrained_model = keras.saving.load_model('classification_model.keras')\n",
    "\n",
    "print(\"Pre-trained model loaded successufully\")\n",
    "\n",
    "# Further train the loaded model\n",
    "pretrained_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores_20_epochs = pretrained_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy_10_epochs: {}% \\n Accuracy_20_epochs: {}'.format(scores[1], scores_20_epochs[1]))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by [Alex Aklson](https://www.linkedin.com/in/aklson/). I hope you found this lab interesting and educational. Feel free to contact me if you have any questions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2024-11-20  | 3.0  |   Aman   |  Updated the library versions to current |\n",
    "| 2020-09-21  | 2.0  | Srishti  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
    "\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "## <h3 align=\"center\">  IBM Corporation. All rights reserved. <h3/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\"> &#169; IBM Corporation. All rights reserved. <h3/>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "prev_pub_hash": "c850b639d611b84ea2eecf5ddb84ea433849e20b6766a84b43a9df0c51e4e9ee"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
